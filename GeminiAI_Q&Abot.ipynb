{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAvFV7NWxSJN",
        "outputId": "f9034aaf-0f31-43ef-9983-f5094e4104d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.34.0-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.34.0 watchdog-4.0.0\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[31;40mERR!\u001b[0m \u001b[0m\u001b[35mcode\u001b[0m E404\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[31;40mERR!\u001b[0m \u001b[0m\u001b[35m404\u001b[0m Not Found - GET https://registry.npmjs.org/localtunel - Not found\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[31;40mERR!\u001b[0m \u001b[0m\u001b[35m404\u001b[0m \n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[31;40mERR!\u001b[0m \u001b[0m\u001b[35m404\u001b[0m  'localtunel@latest' is not in the npm registry.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[31;40mERR!\u001b[0m \u001b[0m\u001b[35m404\u001b[0m You should bug the author to publish it (or use the name yourself!)\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[31;40mERR!\u001b[0m \u001b[0m\u001b[35m404\u001b[0m \n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[31;40mERR!\u001b[0m \u001b[0m\u001b[35m404\u001b[0m Note that you can also install from a\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[31;40mERR!\u001b[0m \u001b[0m\u001b[35m404\u001b[0m tarball, folder, http url, or git url.\n",
            "\u001b[0m\n",
            "\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[31;40mERR!\u001b[0m\u001b[35m\u001b[0m A complete log of this run can be found in:\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[31;40mERR!\u001b[0m\u001b[35m\u001b[0m     /root/.npm/_logs/2024-05-18T17_36_10_089Z-debug.log\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "api_key=\"AIzaSyDFpYzy_niO4FSCcB1aNbu7t-SUhNgoykY\"\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "eWKyYqREzHSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel(\"gemini-pro\")\n",
        "chat = model.start_chat(history=[])\n",
        "chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUqEgyKyzKRI",
        "outputId": "ba7cc99f-ed87-409d-f004-9a2367bb04fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatSession(\n",
              "    model=genai.GenerativeModel(\n",
              "        model_name='models/gemini-pro',\n",
              "        generation_config={},\n",
              "        safety_settings={},\n",
              "        tools=None,\n",
              "        system_instruction=None,\n",
              "        cached_content=None\n",
              "    ),\n",
              "    history=[]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel(\"gemini-pro\")\n",
        "chat = model.start_chat(history=[])\n",
        "response=chat.send_message(\"who is indian ICT Captain\")\n",
        "response.text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N8zkuTFlV7pO",
        "outputId": "aade07ea-88c7-4001-9711-0f058b0a240f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sourav Ganguly'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=chat.send_message(\"How old he?\")\n",
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SIllqX1wWSqe",
        "outputId": "4df83be3-eba1-4564-dccb-200cffd937e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'51 years old (as of 2023)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=chat.send_message(\"But he is retried now, He is not a captain anymore?\")\n",
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "cil737BdWcLs",
        "outputId": "d419560f-353b-40f4-af0e-2febe5dc447e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, Sourav Ganguly is retired from international cricket and is no longer the captain of the Indian cricket team. He retired from all forms of cricket in 2008.\\n\\nHowever, he is still actively involved in cricket as an administrator and commentator. He is currently the President of the Board of Control for Cricket in India (BCCI).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel(\"gemini-pro\") # Gemini pro model\n",
        "chat = model.start_chat(history=[]) # Model start chat, save the chat history\n",
        "while True: # I want to ask many ask while loop\n",
        "    qn=input(\"enter a question:\") # we are enter the qn\n",
        "    if qn!=\"Done\":  # If that qn not equal done , you can give the response\n",
        "        response=chat.send_message(qn,stream=True)\n",
        "        for chunk in response:\n",
        "            print(chunk.text)\n",
        "    else:\n",
        "        break\n",
        "# Outdated data\n",
        "# ChatGPT Gemin model\n",
        "# 2015-16\n",
        "# This is generic chatbot\n",
        "# Healthcare domain\n",
        "# 140crs ====\n",
        "# 5 years == next 5 years\n",
        "# bilol\n",
        "# 25 === 35\n",
        "# 35 === 27\n",
        "# 30  35 === 54kg\n",
        "#  27\n",
        "# BMW 6 google agnts  Langchain RAG"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "Q8fY3hPjzRCH",
        "outputId": "1197f3fd-612f-4a5b-fef3-c3dcefba6523"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter a question:hello\n",
            "Hello! How can I assist you today?\n",
            "enter a question:I need some information\n",
            "What information are you looking for? I can provide information on a wide variety of\n",
            " topics, including current events, weather, sports, and more.\n",
            "enter a question:Tell me about sitaram yechuri\n",
            "**Sitaram Yechury**\n",
            "\n",
            "**Personal Information:**\n",
            "\n",
            "* Born\n",
            ": August 12, 1952, in Vijayawada, Andhra Pradesh, India\n",
            "* Education: Master's degree in Russian Studies\n",
            " from Jawaharlal Nehru University (JNU)\n",
            "* Wife: Seetha Yechury\n",
            "\n",
            "**Political Career:**\n",
            "\n",
            "* Joined the Communist Party of India (Marxist) (CPI(M)) in 1974\n",
            "* Elected as a member of the Lok Sabha (lower house of the Indian Parliament)\n",
            " for the first time in 1998\n",
            "* Served as the General Secretary of the CPI(M) from 2015 to 2022\n",
            "* Currently a member of the Rajya Sabha (upper house of the Indian Parliament)\n",
            "\n",
            "**Political Views and Activism:**\n",
            "\n",
            "* A vocal critic of capitalism and imperialism\n",
            "* Advocates for a socialist and secular India\n",
            "* Supports workers' rights, social justice, and environmental protection\n",
            "* Known for his strong stance against communalism and religious fundamentalism\n",
            "* Participated in numerous social and political movements, including the anti-corruption movement and the farmers' protests\n",
            "\n",
            "\n",
            "**Other Notable Positions:**\n",
            "\n",
            "* Former editor of the CPI(M) weekly newspaper, People's Democracy\n",
            "* President of the India-Russia Friendship Society\n",
            "* Member of the Central Executive Committee of the Communist Party of China\n",
            "\n",
            "**Recognition and Awards:**\n",
            "\n",
            "* Recipient of the Padma Shri, India's fourth highest civilian honor, in 2021\n",
            "* Honored with the Lenin Peace Prize in 2017 for his contributions to international peace and solidarity\n",
            "\n",
            "Sitaram Yechury is known as a charismatic and influential figure in Indian politics, known for his sharp intellect and unwavering commitment to his beliefs.\n",
            "enter a question:Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "api_key=\"AIzaSyBUUejpbU_3eouCT96lkHmkE2mQ6jQb8TU\"\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "## function to load Gemini Pro model and get repsonses\n",
        "model=genai.GenerativeModel(\"gemini-pro\")\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "##initialize our streamlit app\n",
        "\n",
        "st.set_page_config(page_title=\"Q&A Demo\")\n",
        "\n",
        "st.header(\"Gemini LLM Application\")\n",
        "\n",
        "# Initialize session state for chat history if it doesn't exist\n",
        "if 'chat_history' not in st.session_state:\n",
        "    st.session_state['chat_history'] = []\n",
        "\n",
        "input=st.text_input(\"Input: \",key=\"input\")\n",
        "submit=st.button(\"Ask the question\")\n",
        "\n",
        "if submit and input:\n",
        "    response=chat.send_message(input,stream=True)\n",
        "    st.session_state['chat_history'].append((\"You\", input))\n",
        "    st.subheader(\"The Response is\")\n",
        "    for chunk in response:\n",
        "        st.write(chunk.text)\n",
        "        st.session_state['chat_history'].append((\"Bot\", chunk.text))\n",
        "st.subheader(\"The Chat History is\")\n",
        "\n",
        "for role, text in st.session_state['chat_history']:\n",
        "    st.write(f\"{role}: {text}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRCR8WEn0tSj",
        "outputId": "0078e737-5229-45b4-eae8-813186537393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXZ9JOc2xr9R",
        "outputId": "777de2f4-012f-47d6-bc93-11180e519267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "api_key=\"AIzaSyBUUejpbU_3eouCT96lkHmkE2mQ6jQb8TU\"\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "## function to load Gemini Pro model and get repsonses\n",
        "model=genai.GenerativeModel(\"gemini-pro\")\n",
        "chat = model.start_chat(history=[])\n",
        "def get_gemini_response(question):\n",
        "\n",
        "    response=chat.send_message(question,stream=True)\n",
        "    return response\n",
        "\n",
        "##initialize our streamlit app\n",
        "\n",
        "st.set_page_config(page_title=\"Q&A Demo\")\n",
        "\n",
        "st.header(\"Gemini LLM Application\")\n",
        "\n",
        "# Initialize session state for chat history if it doesn't exist\n",
        "if 'chat_history' not in st.session_state:\n",
        "    st.session_state['chat_history'] = []\n",
        "\n",
        "input=st.text_input(\"Input: \",key=\"input\")\n",
        "submit=st.button(\"Ask the question\")\n",
        "\n",
        "if submit and input:\n",
        "    response=get_gemini_response(input)\n",
        "    # Add user query and response to session state chat history\n",
        "    st.session_state['chat_history'].append((\"You\", input))\n",
        "    st.subheader(\"The Response is\")\n",
        "    for chunk in response:\n",
        "        st.write(chunk.text)\n",
        "        st.session_state['chat_history'].append((\"Bot\", chunk.text))\n",
        "st.subheader(\"The Chat History is\")\n",
        "\n",
        "for role, text in st.session_state['chat_history']:\n",
        "    st.write(f\"{role}: {text}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD2sccpbx6fl",
        "outputId": "d5fb9d6d-807a-424b-b18f-33dab6a34233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.196.227.157\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.196.227.157:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.585s\n",
            "your url is: https://fluffy-grapes-know.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmP5wm2izl9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}